Machine Learning Series  
A complete, structured collection of Machine Learning notebooks covering data preprocessing, model building, evaluation, feature engineering, and unsupervised learning.  
This series is designed for beginners and intermediate learners who want practical, hands-on ML understanding with clear examples.

Contents
1. Data Preprocessing
- Handling missing values  
- Encoding categorical features  
- Scaling (Standardization / Normalization)  
- Outlier detection  
- Train-test split  

2. Exploratory Data Analysis (EDA)
- Distribution analysis  
- Correlation heatmaps  
- Statistical summaries  
- Visualization with Matplotlib & Seaborn  

3. Supervised Learning

Classification
- Logistic Regression  
- K-Nearest Neighbors (KNN)  
- Naïve Bayes  
- Support Vector Machines (SVM)  
- Decision Trees  
- Random Forest  
- Ensemble Methods  
  - Voting Classifier  
  - Bagging  
  - Boosting (AdaBoost, Gradient Boosting)

Regression
- Linear Regression  
- Polynomial Regression  
- Lasso, Ridge (Regularization)  
- Decision Tree Regression  
- Random Forest Regression  

4. Unsupervised Learning
- K-Means Clustering  
- DBSCAN  
- Hierarchical Clustering  
- Principal Component Analysis (PCA)
- 
5. Model Evaluation
- Accuracy, Precision, Recall, F1-Score  
- Confusion Matrix  
- ROC/AUC  
- R-squared, RMSE, MAE  
- Cross-validation  

How to Use
1. Clone the repository  
   ```bash
   git clone https://github.com/Laibanasirkhan/Machine-Learning-Series.git
2. Open notebooks in Jupyter / Google Colab  
3. Explore each notebook in order to follow the learning flow  

About This Series
I created this series to strengthen my ML fundamentals and help beginners learn through clear, practical examples.  

Laiba Nasir 
AI Student  


## ⭐ If you find this helpful, feel free to star the repo!
